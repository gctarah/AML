{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccdb7dba",
   "metadata": {},
   "source": [
    "# Diabetes Prediction using Machine Learning\n",
    "\n",
    "Diabetes is a group of metabolic disorders in which there are high blood sugar levels over a prolonged period. \n",
    "Symptoms of high blood sugar include frequent urination, increased thirst, and increased hunger. \n",
    "If left untreated, diabetes can cause many complications such as cardiovascular disease, stroke, kidney disease, \n",
    "foot ulcers, and eye damage.\n",
    "\n",
    "This dataset is from the National Institute of Diabetes and Digestive and Kidney Diseases. \n",
    "The objective is to diagnostically predict whether or not a patient has diabetes based on certain diagnostic measurements.\n",
    "\n",
    "**Objective**: Build a machine learning model to accurately predict whether or not patients have diabetes.\n",
    "\n",
    "**Dataset Details:**\n",
    "- Pregnancies\n",
    "- Glucose\n",
    "- BloodPressure\n",
    "- SkinThickness\n",
    "- Insulin\n",
    "- BMI\n",
    "- DiabetesPedigreeFunction\n",
    "- Age\n",
    "- Outcome (0 or 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f7fde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation of required libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error, r2_score, roc_auc_score, roc_curve, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.simplefilter(action = \"ignore\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d754633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "df = pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687efdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape and info\n",
    "print(df.shape)\n",
    "df.info()\n",
    "df.describe().T\n",
    "df['Outcome'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84096a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram plots\n",
    "df['Age'].hist(edgecolor=\"black\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(4,2, figsize=(16,16))\n",
    "sns.histplot(df.Age, bins=20, ax=ax[0,0]) \n",
    "sns.histplot(df.Pregnancies, bins=20, ax=ax[0,1]) \n",
    "sns.histplot(df.Glucose, bins=20, ax=ax[1,0]) \n",
    "sns.histplot(df.BloodPressure, bins=20, ax=ax[1,1]) \n",
    "sns.histplot(df.SkinThickness, bins=20, ax=ax[2,0])\n",
    "sns.histplot(df.Insulin, bins=20, ax=ax[2,1])\n",
    "sns.histplot(df.DiabetesPedigreeFunction, bins=20, ax=ax[3,0]) \n",
    "sns.histplot(df.BMI, bins=20, ax=ax[3,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4de541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "f, ax = plt.subplots(figsize=[20,15])\n",
    "sns.heatmap(df.corr(), annot=True, fmt=\".2f\", cmap=\"magma\", ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 0 with NaN in some columns\n",
    "df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb18dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with median by class\n",
    "def median_target(var):   \n",
    "    temp = df[df[var].notnull()]\n",
    "    temp = temp[[var, 'Outcome']].groupby(['Outcome'])[[var]].median().reset_index()\n",
    "    return temp\n",
    "\n",
    "columns = df.columns.drop(\"Outcome\")\n",
    "for i in columns:\n",
    "    df.loc[(df['Outcome'] == 0) & (df[i].isnull()), i] = median_target(i)[i][0]\n",
    "    df.loc[(df['Outcome'] == 1) & (df[i].isnull()), i] = median_target(i)[i][1]\n",
    "\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf31784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection using Local Outlier Factor\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "lof = LocalOutlierFactor(n_neighbors=10)\n",
    "lof.fit_predict(df)\n",
    "df_scores = lof.negative_outlier_factor_\n",
    "threshold = np.sort(df_scores)[7]\n",
    "outlier = df_scores > threshold\n",
    "df = df[outlier]\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c74e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "df['NewBMI'] = pd.cut(df['BMI'], bins=[0,18.5,24.9,29.9,34.9,39.9,100], labels=[\"Underweight\",\"Normal\",\"Overweight\",\"Obesity1\",\"Obesity2\",\"Obesity3\"])\n",
    "\n",
    "def set_insulin(row):\n",
    "    if 16 <= row[\"Insulin\"] <= 166:\n",
    "        return \"Normal\"\n",
    "    else:\n",
    "        return \"Abnormal\"\n",
    "df['NewInsulinScore'] = df.apply(set_insulin, axis=1)\n",
    "\n",
    "df['NewGlucose'] = pd.cut(df['Glucose'], bins=[0,70,99,126,200], labels=[\"Low\",\"Normal\",\"Overweight\",\"High\"])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71342595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding categorical features\n",
    "df = pd.get_dummies(df, columns=[\"NewBMI\",\"NewInsulinScore\",\"NewGlucose\"], drop_first=True)\n",
    "y = df[\"Outcome\"]\n",
    "X = df.drop(\"Outcome\", axis=1)\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "transformer = RobustScaler().fit(X)\n",
    "X = pd.DataFrame(transformer.transform(X), columns=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c4691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base models comparison\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(random_state=12345)))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier(random_state=12345)))\n",
    "models.append(('RF', RandomForestClassifier(random_state=12345)))\n",
    "models.append(('SVM', SVC(gamma='auto', random_state=12345)))\n",
    "models.append(('XGB', GradientBoostingClassifier(random_state=12345)))\n",
    "models.append((\"LightGBM\", LGBMClassifier(random_state=12345)))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    cv_results = cross_val_score(model, X, y, cv=10, scoring=\"accuracy\")\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(f\"{name}: {cv_results.mean():.4f} ({cv_results.std():.4f})\")\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.boxplot(results)\n",
    "plt.xticks(range(1,len(names)+1), names)\n",
    "plt.title(\"Algorithm Comparison\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add Gaussian Process Classifier\n",
    "# from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "# gpc = GaussianProcessClassifier().fit(X, y)\n",
    "\n",
    "# TODO: Add Fuzzy Logic classification\n",
    "# Example with scikit-fuzzy (to be implemented)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Gaussian Process Classifiers: RBF vs Matern ---\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, ConstantKernel as C, WhiteKernel\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, confusion_matrix, brier_score_loss\n",
    "import numpy as np\n",
    "\n",
    "# Use the preprocessed X, y from earlier cells. If not present, re-create them.\n",
    "try:\n",
    "    X.shape\n",
    "except NameError:\n",
    "    print(\"X not found - please run previous cells to prepare X and y\")\n",
    "else:\n",
    "    # For GP, reduce dimensionality slightly to avoid slow kernels: use top features by variance\n",
    "    from sklearn.feature_selection import SelectKBest, f_classif\n",
    "    selector = SelectKBest(f_classif, k=min(10, X.shape[1]))\n",
    "    X_sel = selector.fit_transform(X, y)\n",
    "\n",
    "    # Standardize\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler_gp = StandardScaler().fit(X_sel)\n",
    "    Xg = scaler_gp.transform(X_sel)\n",
    "    yg = y.values if hasattr(y, \"values\") else y\n",
    "\n",
    "    Xg_train, Xg_test, yg_train, yg_test = train_test_split(Xg, yg, test_size=0.2, stratify=yg, random_state=42)\n",
    "\n",
    "    kernels = {\n",
    "        \"RBF\": C(1.0)*RBF(length_scale=1.0) + WhiteKernel(noise_level=1.0),\n",
    "        \"Matern\": C(1.0)*Matern(length_scale=1.0, nu=1.5) + WhiteKernel(noise_level=1.0)\n",
    "    }\n",
    "\n",
    "    gp_results = {}\n",
    "    for name, kernel in kernels.items():\n",
    "        print(f\"Training GPC with kernel: {name}\")\n",
    "        gpc = GaussianProcessClassifier(kernel=kernel, max_iter_predict=100)\n",
    "        gpc.fit(Xg_train, yg_train)\n",
    "        prob = gpc.predict_proba(Xg_test)[:,1]\n",
    "        pred = (prob >= 0.5).astype(int)\n",
    "        auc = roc_auc_score(yg_test, prob)\n",
    "        acc = accuracy_score(yg_test, pred)\n",
    "        brier = brier_score_loss(yg_test, prob)\n",
    "        print(f\"{name} - AUC: {auc:.4f}, Acc: {acc:.4f}, Brier: {brier:.4f}\")\n",
    "        gp_results[name] = {\"model\": gpc, \"auc\": auc, \"acc\": acc, \"brier\": brier, \"prob\": prob, \"pred\": pred}\n",
    "\n",
    "    # Compare to Logistic Regression baseline on same features\n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    lr.fit(Xg_train, yg_train)\n",
    "    prob_lr = lr.predict_proba(Xg_test)[:,1]\n",
    "    auc_lr = roc_auc_score(yg_test, prob_lr)\n",
    "    acc_lr = accuracy_score(yg_test, (prob_lr>=0.5).astype(int))\n",
    "    print(f\"LogisticRegression - AUC: {auc_lr:.4f}, Acc: {acc_lr:.4f}\")\n",
    "\n",
    "    # Summary table\n",
    "    import pandas as pd\n",
    "    summary = pd.DataFrame([\n",
    "        {\"method\":\"LogisticRegression\",\"auc\":auc_lr,\"acc\":acc_lr,\"brier\":brier_score_loss(yg_test, prob_lr)}\n",
    "    ] + [{\"method\":k,\"auc\":v[\"auc\"],\"acc\":v[\"acc\"],\"brier\":v[\"brier\"]} for k,v in gp_results.items()])\n",
    "    display(summary.sort_values(\"auc\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a41471",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Gaussian Process Regression: Predict Glucose ---\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, ConstantKernel as C, WhiteKernel\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Prepare regression dataset: predict Glucose from other clinical features\n",
    "if 'df' not in globals():\n",
    "    print(\"Dataframe df not found. Please run earlier cells.\")\n",
    "else:\n",
    "    reg_features = ['Pregnancies','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']\n",
    "    # ensure no NaNs (should be imputed earlier)\n",
    "    Xr = df[reg_features].copy()\n",
    "    yr = df['Glucose'].copy()\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    Xr_train, Xr_test, yr_train, yr_test = train_test_split(Xr, yr, test_size=0.2, random_state=42)\n",
    "    scaler_r = StandardScaler().fit(Xr_train)\n",
    "    Xr_train_s = scaler_r.transform(Xr_train)\n",
    "    Xr_test_s = scaler_r.transform(Xr_test)\n",
    "\n",
    "    kernels_r = {\n",
    "        \"RBF\": C(1.0)*RBF(length_scale=np.ones(Xr_train_s.shape[1])),\n",
    "        \"Matern\": C(1.0)*Matern(length_scale=np.ones(Xr_train_s.shape[1]), nu=1.5)\n",
    "    }\n",
    "\n",
    "    gpr_results = {}\n",
    "    for name,kernel in kernels_r.items():\n",
    "        print(f\"Training GPR with kernel: {name}\")\n",
    "        gpr = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, n_restarts_optimizer=3, normalize_y=True, random_state=42)\n",
    "        gpr.fit(Xr_train_s, yr_train)\n",
    "        ypred, ystd = gpr.predict(Xr_test_s, return_std=True)\n",
    "        rmse = np.sqrt(mean_squared_error(yr_test, ypred))\n",
    "        r2 = r2_score(yr_test, ypred)\n",
    "        print(f\"{name} - RMSE: {rmse:.4f}, R2: {r2:.4f}\")\n",
    "        gpr_results[name] = {\"model\": gpr, \"rmse\": rmse, \"r2\": r2, \"ypred\": ypred, \"ystd\": ystd}\n",
    "\n",
    "    # Plot predicted vs true for best model by RMSE\n",
    "    best_name = min(gpr_results, key=lambda k: gpr_results[k]['rmse'])\n",
    "    best = gpr_results[best_name]\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.errorbar(np.arange(len(best['ypred'])), best['ypred'], yerr=best['ystd'], fmt='x', label='pred')\n",
    "    plt.scatter(np.arange(len(best['ypred'])), yr_test.values, marker='o', facecolors='none', edgecolors='r', label='true')\n",
    "    plt.legend(); plt.title(f'GPR predictions ({best_name})'); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c8d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Fuzzy Logic: Mamdani baseline and simple tuning ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# Prepare inputs: use BMI and Age as core inputs (from df)\n",
    "if 'df' not in globals():\n",
    "    print(\"df not present. Run earlier cells.\")\n",
    "else:\n",
    "    bmi_vals = df['BMI'].values\n",
    "    age_vals = df['Age'].values\n",
    "    outcomes = df['Outcome'].values\n",
    "\n",
    "    # Normalize ranges for universes\n",
    "    bmi_univ = np.arange(10, 51, 1)\n",
    "    age_univ = np.arange(10, 101, 1)\n",
    "    risk_univ = np.arange(0, 101, 1)\n",
    "\n",
    "    def build_mamdani(bmi_thresh_obese=30, age_thresh_senior=55):\n",
    "        # Create fuzzy variables\n",
    "        bmi = ctrl.Antecedent(bmi_univ, 'bmi')\n",
    "        age = ctrl.Antecedent(age_univ, 'age')\n",
    "        risk = ctrl.Consequent(risk_univ, 'risk')\n",
    "\n",
    "        # BMI membership: under/normal/over/obese using thresholds\n",
    "        bmi['under'] = fuzz.trimf(bmi.universe, [10, 15, 18.5])\n",
    "        bmi['normal'] = fuzz.trimf(bmi.universe, [18.5, 22.5, 25])\n",
    "        bmi['over'] = fuzz.trimf(bmi.universe, [24, 27.5, 30])\n",
    "        bmi['obese'] = fuzz.trimf(bmi.universe, [bmi_thresh_obese-2, bmi_thresh_obese, 50])\n",
    "\n",
    "        # Age membership\n",
    "        age['young'] = fuzz.trimf(age.universe, [10, 20, 30])\n",
    "        age['adult'] = fuzz.trimf(age.universe, [25, 40, 55])\n",
    "        age['senior'] = fuzz.trimf(age.universe, [age_thresh_senior-10, age_thresh_senior, 100])\n",
    "\n",
    "        # Risk membership\n",
    "        risk['low'] = fuzz.trimf(risk.universe, [0, 10, 40])\n",
    "        risk['medium'] = fuzz.trimf(risk.universe, [30, 50, 70])\n",
    "        risk['high'] = fuzz.trimf(risk.universe, [60, 80, 100])\n",
    "\n",
    "        # Rules\n",
    "        rules = [\n",
    "            ctrl.Rule(bmi['obese'] & age['senior'], risk['high']),\n",
    "            ctrl.Rule(bmi['obese'] & age['adult'], risk['high']),\n",
    "            ctrl.Rule(bmi['over'] & age['senior'], risk['high']),\n",
    "            ctrl.Rule(bmi['normal'] & age['adult'], risk['medium']),\n",
    "            ctrl.Rule(bmi['under'] & age['young'], risk['low']),\n",
    "            ctrl.Rule(bmi['over'] & age['young'], risk['medium'])\n",
    "        ]\n",
    "\n",
    "        system = ctrl.ControlSystem(rules)\n",
    "        sim = ctrl.ControlSystemSimulation(system)\n",
    "        return sim\n",
    "\n",
    "    # Baseline Mamdani\n",
    "    sim_base = build_mamdani()\n",
    "    fuzz_scores = []\n",
    "    for bi, ag in zip(bmi_vals, age_vals):\n",
    "        sim_base.input['bmi'] = bi\n",
    "        sim_base.input['age'] = ag\n",
    "        sim_base.compute()\n",
    "        fuzz_scores.append(sim_base.output['risk'])\n",
    "\n",
    "    # Evaluate baseline by AUC (threshold risk>50)\n",
    "    try:\n",
    "        auc_base = roc_auc_score(outcomes, np.array(fuzz_scores)/100.0)\n",
    "    except Exception as e:\n",
    "        auc_base = None\n",
    "    print(\"Baseline Mamdani approx AUC (risk normalized):\", auc_base)\n",
    "\n",
    "    # Simple tuning: grid search over bmi_thresh_obese and age_thresh_senior to maximize AUC\n",
    "    best_auc = -1\n",
    "    best_params = None\n",
    "    params_tested = []\n",
    "    for bmi_t in range(28,35):\n",
    "        for age_t in range(50,66,5):\n",
    "            sim_t = build_mamdani(bmi_thresh_obese=bmi_t, age_thresh_senior=age_t)\n",
    "            scores = []\n",
    "            for bi, ag in zip(bmi_vals, age_vals):\n",
    "                sim_t.input['bmi'] = bi\n",
    "                sim_t.input['age'] = ag\n",
    "                sim_t.compute()\n",
    "                scores.append(sim_t.output['risk'])\n",
    "            try:\n",
    "                auc = roc_auc_score(outcomes, np.array(scores)/100.0)\n",
    "            except Exception:\n",
    "                auc = -1\n",
    "            params_tested.append((bmi_t, age_t, auc))\n",
    "            if auc > best_auc:\n",
    "                best_auc = auc\n",
    "                best_params = (bmi_t, age_t)\n",
    "    print(\"Best tuned Mamdani params:\", best_params, \"AUC:\", best_auc)\n",
    "\n",
    "    # Build tuned sim and get final scores\n",
    "    sim_tuned = build_mamdani(bmi_thresh_obese=best_params[0], age_thresh_senior=best_params[1])\n",
    "    tuned_scores = []\n",
    "    for bi, ag in zip(bmi_vals, age_vals):\n",
    "        sim_tuned.input['bmi'] = bi\n",
    "        sim_tuned.input['age'] = ag\n",
    "        sim_tuned.compute()\n",
    "        tuned_scores.append(sim_tuned.output['risk'])\n",
    "\n",
    "    # Compare baseline and tuned by AUC and correlation with Outcome\n",
    "    from scipy.stats import pearsonr\n",
    "    corr_base = pearsonr(np.array(fuzz_scores), outcomes)[0]\n",
    "    corr_tuned = pearsonr(np.array(tuned_scores), outcomes)[0]\n",
    "    print(\"Correlation base:\", corr_base, \"tuned:\", corr_tuned)\n",
    "    print(\"AUC base:\", auc_base, \"AUC tuned:\", best_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ac19e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Summary: Compare GP, GPR, and Fuzzy ---\n",
    "print('GP Classifier results and comparison table should appear above.')\n",
    "try:\n",
    "    display(summary)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print('\\\\nGPR regression results (Glucose) - review RMSE/R2 above.')\n",
    "print('\\\\nFuzzy logic: baseline and tuned AUC and correlations printed above.')\n",
    "\n",
    "# Save tuned fuzzy scores and best GP probabilities to CSV for further reporting if available\n",
    "try:\n",
    "    df_out = df.copy()\n",
    "    df_out['fuzzy_tuned'] = np.array(tuned_scores)\n",
    "    # if gp_results exists, add prob from best GP (Matern or RBF)\n",
    "    best_gp_name = max(gp_results, key=lambda k: gp_results[k]['auc']) if 'gp_results' in globals() else None\n",
    "    if best_gp_name:\n",
    "        df_out['gp_prob_'+best_gp_name] = np.nan\n",
    "        # map test indices - simpler: recompute on whole Xg scaled set (not advised but quick)\n",
    "        Xg_all = scaler_gp.transform(selector.transform(X))\n",
    "        df_out['gp_prob_'+best_gp_name] = gp_results[best_gp_name]['model'].predict_proba(Xg_all)[:,1]\n",
    "    df_out.to_csv('diabetes_with_fuzzy_gp.csv', index=False)\n",
    "    print('Saved diabetes_with_fuzzy_gp.csv')\n",
    "except Exception as e:\n",
    "    print('Could not save output CSV:', e)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
